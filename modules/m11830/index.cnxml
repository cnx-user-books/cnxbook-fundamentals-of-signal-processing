<document xmlns="http://cnx.rice.edu/cnxml" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:md="http://cnx.rice.edu/mdml" xmlns:bib="http://bibtexml.sf.net/">
  <title>First Order Convergence Analysis of the LMS Algorithm</title>
  <metadata><md:content-id>undefined</md:content-id><md:title/><md:uuid>c3f0f2ea-28f1-45ba-a081-77b28f585e24</md:uuid>
</metadata>

  <content>
    <section id="sect3">
      <title>Analysis of the LMS algorithm</title>
      <para id="para1">
	It is important to analyze the LMS algorithm to determine
      under what conditions it is stable, whether or not it converges
      to the Wiener solution, to determine how quickly it converges,
      how much degredation is suffered due to the noisy gradient,
      etc. In particular, we need to know how to choose the parameter
      <m:math><m:ci>μ</m:ci></m:math>.
      </para>
      <section id="secta">
	<title>Mean of W</title>
	<para id="para2">
	  does
	  <m:math>
	    <m:ci>
	      <m:msup>
		<m:mi>W</m:mi>
		<m:mi>k</m:mi>
	      </m:msup>
	    </m:ci>
	  </m:math>,
	  <m:math>
	    <m:apply>
	      <m:tendsto/>
	      <m:ci>k</m:ci>
	      <m:infinity/>
	    </m:apply>
	  </m:math> approach the Wiener solution? (since 
	  <m:math>
	    <m:ci>
	      <m:msup>
		<m:mi>W</m:mi>
		<m:mi>k</m:mi>
	      </m:msup>
	    </m:ci>
	  </m:math> is always somewhat random in the approximate
	  gradient-based LMS algorithm, we ask whether the expected
	  value of the filter coefficients converge to the Wiener
	  solution)
	  <equation id="eq1">
	    <m:math>
	      <m:apply>
		<m:eq/>
		<m:apply>
		  <m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#expectedvalue"/>
		  <m:ci>
		    <m:msup>
		      <m:mi>W</m:mi>
		      <m:mrow>
			<m:mi>k</m:mi>
			<m:mo>+</m:mo>
			<m:mn>1</m:mn>
		      </m:mrow>
		    </m:msup>
		  </m:ci>
		</m:apply>
		<m:apply>
		  <m:conjugate/>
		  <m:ci>
		    <m:msup>
		      <m:mi>W</m:mi>
		      <m:mrow>
			<m:mi>k</m:mi>
			<m:mo>+</m:mo>
			<m:mn>1</m:mn>
		      </m:mrow>
		    </m:msup>
		  </m:ci>
		</m:apply>
		<m:apply>
		  <m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#expectedvalue"/>
		  <m:apply>
		    <m:plus/>
		    <m:ci>
		      <m:msup>
			<m:mi>W</m:mi>
			<m:mi>k</m:mi>
		      </m:msup>
		    </m:ci>
		    <m:apply>
		      <m:times/>
		      <m:cn>2</m:cn>
		      <m:ci>μ</m:ci>
		      <m:ci>
			<m:msub>
			  <m:mi>ε</m:mi>
			  <m:mi>k</m:mi>
			</m:msub>
		      </m:ci>
		      <m:ci>
			<m:msup>
			  <m:mi>X</m:mi>
			  <m:mi>k</m:mi>
			</m:msup>
		      </m:ci>
		    </m:apply>
		  </m:apply>
		</m:apply>
		<m:apply>
		  <m:plus/>
		  <m:apply>
		    <m:conjugate/>
		    <m:ci>
		      <m:msup>
			<m:mi>W</m:mi>
			<m:mi>k</m:mi>
		      </m:msup>
		    </m:ci>
		  </m:apply>
		  <m:apply>
		    <m:times/>
		    <m:cn>2</m:cn>
		    <m:ci>μ</m:ci>
		    <m:apply>
		      <m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#expectedvalue"/>
		      <m:apply>
			<m:times/>
			<m:ci>
			  <m:msub>
			    <m:mi>d</m:mi>
			    <m:mi>k</m:mi>
			  </m:msub>
			</m:ci>
			<m:ci>
			  <m:msup>
			    <m:mi>X</m:mi>
			    <m:mi>k</m:mi>
			  </m:msup>
			</m:ci>
		      </m:apply>
		    </m:apply>
		  </m:apply>
		  <m:apply>
		    <m:times/>
		    <m:cn>2</m:cn>
		    <m:ci>μ</m:ci>
		    <m:apply>
		      <m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#expectedvalue"/>
		      <m:apply>
			<m:minus/>
			<m:apply>
			  <m:times/>
			  <m:apply>
			    <m:times/>
			    <m:apply>
			      <m:transpose/>
			      <m:ci>
				<m:msup>
				  <m:mi>W</m:mi>
				  <m:mi>k</m:mi>
				</m:msup>
			      </m:ci>
			    </m:apply>
			    <m:ci>
			      <m:msup>
				<m:mi>X</m:mi>
				<m:mi>k</m:mi>
			      </m:msup>
			    </m:ci>
			  </m:apply>
			  <m:ci>
			    <m:msup>
			      <m:mi>X</m:mi>
			      <m:mi>k</m:mi>
			    </m:msup>
			  </m:ci>
			</m:apply>
		      </m:apply>
		    </m:apply>
		  </m:apply>
		</m:apply>
		<m:apply>
		  <m:plus/>
		  <m:apply>
		    <m:conjugate/>
		    <m:ci>
		      <m:msup>
			<m:mi>W</m:mi>
			<m:mi>k</m:mi>
		      </m:msup>
		    </m:ci>
		  </m:apply>
		  <m:apply>
		    <m:times/>
		    <m:cn>2</m:cn>
		    <m:ci>μ</m:ci>
		    <m:ci>P</m:ci>
		  </m:apply>
		  <m:apply>
		    <m:minus/>
		    <m:apply>
		      <m:times/>
		      <m:cn>2</m:cn>
		      <m:ci>μ</m:ci>
		      <m:apply>
			<m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#expectedvalue"/>
			<m:apply>
			  <m:times/>
			  <m:apply>
			    <m:times/>
			    <m:apply>
			      <m:transpose/>
			      <m:ci>
				<m:msup>
				  <m:mi>W</m:mi>
				  <m:mi>k</m:mi>
				</m:msup>
			      </m:ci>
			    </m:apply>
			    <m:ci>
			      <m:msup>
				<m:mi>X</m:mi>
				<m:mi>k</m:mi>
			      </m:msup>
			    </m:ci>
			  </m:apply>
			  <m:ci>
			    <m:msup>
			      <m:mi>X</m:mi>
			      <m:mi>k</m:mi>
			    </m:msup>
			  </m:ci>
			</m:apply>
		      </m:apply>
		    </m:apply>
		  </m:apply>
		</m:apply>
	      </m:apply>
	    </m:math>
	  </equation>
	</para>
	<section id="assumpsect">
	  <title>Patently False Assumption</title>
	  <para id="para4">
	    <m:math>
	      <m:ci>
		<m:msup>
		  <m:mi>X</m:mi>
		  <m:mi>k</m:mi>
		</m:msup>
	      </m:ci>
	    </m:math> and 
	    <m:math>
	      <m:ci>
		<m:msup>
		  <m:mi>X</m:mi>
		  <m:mrow>
		    <m:mi>k</m:mi>
		    <m:mo>-</m:mo>
		    <m:mi>i</m:mi>
		  </m:mrow>
		</m:msup>
	      </m:ci>
	    </m:math>, 
	    <m:math>
	      <m:ci>
		<m:msup>
		  <m:mi>X</m:mi>
		  <m:mi>k</m:mi>
		</m:msup>
	      </m:ci>
	    </m:math> and 
	    <m:math>
	      <m:ci>
		<m:msup>
		  <m:mi>d</m:mi>
		  <m:mrow>
		    <m:mi>k</m:mi>
		    <m:mo>-</m:mo>
		    <m:mi>i</m:mi>
		  </m:mrow>
		</m:msup>
	      </m:ci>
	    </m:math>, and
	    <m:math>
	      <m:ci>
		<m:msub>
		  <m:mi>d</m:mi>
		  <m:mi>k</m:mi>
		</m:msub>
	      </m:ci>
	    </m:math> and 
	    <m:math>
	      <m:ci>
		<m:msub>
		  <m:mi>d</m:mi>
		  <m:mrow>
		    <m:mi>k</m:mi>
		    <m:mo>-</m:mo>
		    <m:mi>i</m:mi>
		  </m:mrow>
		</m:msub>
	      </m:ci>
	    </m:math> are statistically independent,
	    <m:math>
	      <m:apply>
		<m:neq/>
		<m:ci>i</m:ci>
		<m:cn>0</m:cn>
	      </m:apply>
	    </m:math>. This assumption is obviously false, since 
	    <m:math>
	      <m:ci>
		<m:msup>
		  <m:mi>X</m:mi>
		  <m:mrow>
		    <m:mi>k</m:mi>
		    <m:mo>-</m:mo>
		    <m:mn>1</m:mn>
		  </m:mrow>
		</m:msup>
	      </m:ci>
	    </m:math> is the same as 
	    <m:math>
	      <m:ci>
		<m:msup>
		  <m:mi>X</m:mi>
		  <m:mi>k</m:mi>
		</m:msup>
	      </m:ci>
	    </m:math> except for shifting down the vector elements one
	    place and adding one new sample. We make this assumption
	    because otherwise it becomes extremely difficult to
	    analyze the LMS algorithm. (First good analysis not making
	    this assumption: <cite target-id="MacchiandEweda"><cite-title>Macchi and
	    Eweda</cite-title></cite>) Many simulations and much practical
	    experience has shown that the results one obtains with
	    analyses based on the patently false assumption above are
	    quite accurate in most situations
	  </para>
	  <para id="para5">
	    With the independence assumption, 
	    <m:math>
	      <m:ci>
		<m:msup>
		  <m:mi>W</m:mi>
		  <m:mi>k</m:mi>
		</m:msup>
	      </m:ci>
	    </m:math> (which depends only on previous
	    <m:math>
	      <m:ci>
		<m:msup>
		  <m:mi>X</m:mi>
		  <m:mrow>
		    <m:mi>k</m:mi>
		    <m:mo>-</m:mo>
		    <m:mi>i</m:mi>
		  </m:mrow>
		</m:msup>
	      </m:ci>
	    </m:math>,
	    <m:math>
	      <m:ci>
		<m:msup>
		  <m:mi>d</m:mi>
		  <m:mrow>
		    <m:mi>k</m:mi>
		    <m:mo>-</m:mo>
		    <m:mi>i</m:mi>
		  </m:mrow>
		</m:msup>
	      </m:ci>
	    </m:math>) is statitically independent of 
	    <m:math>
	      <m:ci>
		<m:msup>
		  <m:mi>X</m:mi>
		  <m:mi>k</m:mi>
		</m:msup>
	      </m:ci>
	    </m:math>, and we can simplify
	    <m:math>
	      <m:apply>
		<m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#expectedvalue"/>
		<m:apply>
		  <m:times/>
		  <m:apply>
		    <m:times/>
		    <m:apply>
		      <m:transpose/>
		      <m:ci>
			<m:msup>
			  <m:mi>W</m:mi>
			  <m:mi>k</m:mi>
			</m:msup>
		      </m:ci>
		    </m:apply>
		    <m:ci>
		      <m:msup>
			<m:mi>X</m:mi>
			<m:mi>k</m:mi>
		      </m:msup>
		    </m:ci>
		  </m:apply>
		  <m:ci>
		    <m:msup>
		      <m:mi>X</m:mi>
		      <m:mi>k</m:mi>
		    </m:msup>
		  </m:ci>
		</m:apply>
	      </m:apply>
	    </m:math>
	  </para>
	  <para id="para6">
	    Now 
	    <m:math>
	      <m:apply>
		<m:times/>
		<m:apply>
		  <m:times/>
		  <m:apply>
		    <m:transpose/>
		    <m:ci>
		      <m:msup>
			<m:mi>W</m:mi>
			<m:mi>k</m:mi>
		      </m:msup>
		    </m:ci>
		  </m:apply>
		  <m:ci>
		    <m:msup>
		      <m:mi>X</m:mi>
		      <m:mi>k</m:mi>
		    </m:msup>
		  </m:ci>
		</m:apply>
		<m:ci>
		  <m:msup>
		    <m:mi>X</m:mi>
		    <m:mi>k</m:mi>
		  </m:msup>
		</m:ci>
	      </m:apply>
	    </m:math> is a vector, and
	    <equation id="eq3">
	      <m:math>
		<m:apply>
		  <m:eq/>
		  <m:apply>
		    <m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#expectedvalue"/>
		    <m:apply>
		      <m:times/>
		      <m:apply>
			<m:times/>
			<m:apply>
			  <m:transpose/>
			  <m:ci>
			    <m:msup>
			      <m:mi>W</m:mi>
			      <m:mi>k</m:mi>
			    </m:msup>
			  </m:ci>
			</m:apply>
			<m:ci>
			  <m:msup>
			    <m:mi>X</m:mi>
			    <m:mi>k</m:mi>
			  </m:msup>
			</m:ci>
		      </m:apply>
		      <m:ci>
			<m:msup>
			  <m:mi>X</m:mi>
			  <m:mi>k</m:mi>
			</m:msup>
		      </m:ci>
		    </m:apply>
		  </m:apply>
		  <m:apply>
		    <m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#expectedvalue"/>
		    <m:vector>
		      <m:ci>⋮</m:ci>
		      <m:apply>
			<m:times/>
			<m:apply>
			  <m:sum/>
			  <m:bvar>
			    <m:ci>i</m:ci>
			  </m:bvar>
			  <m:uplimit>
			    <m:apply>
			      <m:minus/>
			      <m:ci>M</m:ci>
			      <m:cn>1</m:cn>
			    </m:apply>
			  </m:uplimit>
			  <m:lowlimit>
			    <m:cn>0</m:cn>
			  </m:lowlimit>
			  <m:apply>
			    <m:times/>
			    <m:ci>
			      <m:msubsup>
				<m:mi>w</m:mi>
				<m:mi>i</m:mi>
				<m:mi>k</m:mi>
			      </m:msubsup>
			    </m:ci>
			    <m:ci>
			      <m:msub>
				<m:mi>x</m:mi>
				<m:mrow>
				  <m:mi>k</m:mi>
				  <m:mo>-</m:mo>
				  <m:mi>i</m:mi>
				</m:mrow>
			      </m:msub>
			    </m:ci>
			  </m:apply>
			</m:apply>
			<m:ci>
			  <m:msub>
			    <m:mi>x</m:mi>
			    <m:mrow>
			      <m:mi>k</m:mi>
			      <m:mo>-</m:mo>
			      <m:mi>j</m:mi>
			    </m:mrow>
			  </m:msub>
			</m:ci>
		      </m:apply>
		      <m:ci>⋮</m:ci>
		    </m:vector>
		  </m:apply>
		  <m:vector>
		    <m:ci>⋮</m:ci>
		    <m:apply>
		      <m:sum/>
		      <m:bvar>
			<m:ci>i</m:ci>
		      </m:bvar>
		      <m:uplimit>
			<m:apply>
			  <m:minus/>
			  <m:ci>M</m:ci>
			  <m:cn>1</m:cn>
			</m:apply>
		      </m:uplimit>
		      <m:lowlimit>
			<m:cn>0</m:cn>
		      </m:lowlimit>
		      <m:apply>
			<m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#expectedvalue"/>
			<m:apply>
			  <m:times/>
			  <m:ci>
			    <m:msubsup>
			      <m:mi>w</m:mi>
			      <m:mi>i</m:mi>
			      <m:mi>k</m:mi>
			    </m:msubsup>
			  </m:ci>
			  <m:ci>
			    <m:msub>
			      <m:mi>x</m:mi>
			      <m:mrow>
				<m:mi>k</m:mi>
				<m:mo>-</m:mo>
				<m:mi>i</m:mi>
			      </m:mrow>
			    </m:msub>
			  </m:ci>
			  <m:ci>
			    <m:msub>
			      <m:mi>x</m:mi>
			      <m:mrow>
				<m:mi>k</m:mi>
				<m:mo>-</m:mo>
				<m:mi>j</m:mi>
			      </m:mrow>
			    </m:msub>
			  </m:ci>
			</m:apply>
		      </m:apply>
		    </m:apply>
		    <m:ci>⋮</m:ci>
		  </m:vector>
		  <m:vector>
		    <m:ci>⋮</m:ci>
		    <m:apply>
		      <m:sum/>
		      <m:bvar>
			<m:ci>i</m:ci>
		      </m:bvar>
		      <m:uplimit>
			<m:apply>
			  <m:minus/>
			  <m:ci>M</m:ci>
			  <m:cn>1</m:cn>
			</m:apply>
		      </m:uplimit>
		      <m:lowlimit>
			<m:cn>0</m:cn>
		      </m:lowlimit>
		      <m:apply>
			<m:times/>
			<m:apply>
			  <m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmat.ocd#expectedvalue"/>
			  <m:ci>
			    <m:msubsup>
			      <m:mi>w</m:mi>
			      <m:mi>i</m:mi>
			      <m:mi>k</m:mi>
			    </m:msubsup>
			  </m:ci>
			</m:apply>
			<m:apply>
			  <m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#expectedvalue"/>
			  <m:apply>
			    <m:times/>
			    <m:ci>
			      <m:msub>
				<m:mi>x</m:mi>
				<m:mrow>
				  <m:mi>k</m:mi>
				  <m:mo>-</m:mo>
				  <m:mi>i</m:mi>
				</m:mrow>
			      </m:msub>
			    </m:ci>
			    <m:ci>
			      <m:msub>
				<m:mi>x</m:mi>
				<m:mrow>
				  <m:mi>k</m:mi>
				  <m:mo>-</m:mo>
				  <m:mi>j</m:mi>
				</m:mrow>
			      </m:msub>
			    </m:ci>
			  </m:apply>
			</m:apply>
		      </m:apply>
		    </m:apply>
		    <m:ci>⋮</m:ci>
		  </m:vector>
		  <m:vector>
		    <m:ci>⋮</m:ci>
		    <m:apply>
		      <m:sum/>
		      <m:bvar>
			<m:ci>i</m:ci>
		      </m:bvar>							
		      <m:uplimit>
			<m:apply>
			  <m:minus/>
			  <m:ci>M</m:ci>
			  <m:cn>1</m:cn>
			</m:apply>
		      </m:uplimit>
		      <m:lowlimit>
			<m:cn>0</m:cn>
		      </m:lowlimit>
		      <m:apply>
			<m:times/>
			<m:apply>
			  <m:conjugate/>
			  <m:ci>
			    <m:msubsup>
			      <m:mi>w</m:mi>
			      <m:mi>i</m:mi>
			      <m:mi>k</m:mi>
			    </m:msubsup>
			  </m:ci>
			</m:apply>
			<m:apply>
			  <m:ci type="fn">
			    <m:msub>
			      <m:mi>r</m:mi>
			      <m:mi>xx</m:mi>
			    </m:msub>
			  </m:ci>
			  <m:apply>
			    <m:minus/>
			    <m:ci>i</m:ci>
			    <m:ci>j</m:ci>
			  </m:apply>
			</m:apply>
		      </m:apply>
		    </m:apply>
		    <m:ci>⋮</m:ci>
		  </m:vector>
		  <m:apply>
		    <m:times/>
		    <m:ci type="matrix">R</m:ci>
		    <m:apply>
		      <m:conjugate/>
		      <m:ci>
			<m:msup>
			  <m:mi>W</m:mi>
			  <m:mi>k</m:mi>
			</m:msup>
		      </m:ci>
		    </m:apply>
		  </m:apply>
		</m:apply>
	      </m:math>
	    </equation> where
	    <m:math>
	      <m:apply>
		<m:eq/>
		<m:ci type="matrix">R</m:ci>
		<m:apply>
		  <m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#expectedvalue"/>
		  <m:apply>
		    <m:times/>
		    <m:ci>
		      <m:msup>
			<m:mi>X</m:mi>
			<m:mi>k</m:mi>
		      </m:msup>
		    </m:ci>
		    <m:apply>
		      <m:transpose/>
		      <m:ci>
			<m:msup>
			  <m:mi>X</m:mi>
			  <m:mi>k</m:mi>
			</m:msup>
		      </m:ci>
		    </m:apply>
		  </m:apply>
		</m:apply>
	      </m:apply>
	    </m:math> is the data correlation matrix.
	  </para>
	  <para id="para7">
	    Putting this back into our equation
	    <equation id="eq4">
	      <m:math>
		<m:apply>
		  <m:eq/>
		  <m:apply>
		    <m:mean/>
		    <m:ci>
		      <m:msup>
			<m:mi>W</m:mi>
			<m:mrow>
			  <m:mi>k</m:mi>
			  <m:mo>+</m:mo>
			  <m:mn>1</m:mn>
			</m:mrow>
		      </m:msup>
		    </m:ci>
		  </m:apply>
		  <m:apply>
		    <m:plus/>
		    <m:apply>
		      <m:mean/>
		      <m:ci>
			<m:msup>
			  <m:mi>W</m:mi>
			  <m:mi>k</m:mi>
			</m:msup>
		      </m:ci>
		    </m:apply>
		    <m:apply>
		      <m:times/>
		      <m:cn>2</m:cn>
		      <m:ci>μ</m:ci>
		      <m:ci>P</m:ci>
		    </m:apply>
		    <m:apply>
		      <m:minus/>
		      <m:apply>
			<m:times/>
			<m:cn>2</m:cn>
			<m:ci>μ</m:ci>
			<m:ci>R</m:ci>
			<m:apply>
			  <m:mean/>
			  <m:ci>
			    <m:msup>
			      <m:mi>W</m:mi>
			      <m:mi>k</m:mi>
			    </m:msup>
			  </m:ci>
			</m:apply>
		      </m:apply>
		    </m:apply>
		  </m:apply>
		  <m:apply>
		    <m:plus/>
		    <m:apply>
		      <m:times/>
		      <m:apply>
			<m:minus/>
			<m:ci>I</m:ci>
			<m:apply>
			  <m:times/>
			  <m:cn>2</m:cn>
			  <m:ci>μ</m:ci>
			  <m:ci>R</m:ci>
			</m:apply>
		      </m:apply>
		      <m:apply>
			<m:mean/>
			<m:ci>
			  <m:msup>
			    <m:mi>W</m:mi>
			    <m:mi>k</m:mi>
			  </m:msup>
			</m:ci>
		      </m:apply>
		    </m:apply>
		    <m:apply>
		      <m:times/>
		      <m:cn>2</m:cn>
		      <m:ci>μ</m:ci>
		      <m:ci>P</m:ci>
		    </m:apply>
		  </m:apply>
		</m:apply>
	      </m:math>
	    </equation> Now <emphasis>if</emphasis>
	    <m:math>
	      <m:apply>
		<m:mean/>
		<m:ci>
		  <m:msup>
		    <m:mi>W</m:mi>
		    <m:mrow>
		      <m:mi>k</m:mi>
		      <m:mo>→</m:mo>
		      <m:mi>∞</m:mi>
		    </m:mrow>
		  </m:msup>
		</m:ci>
	      </m:apply>
	    </m:math> converges to a vector of finite magnitude
	    ("convergence in the mean"), what does it converge to?
	  </para>
	  <para id="para8">
	    If 
	    <m:math>
	      <m:apply>
		<m:mean/>
		<m:ci>
		  <m:msup>
		    <m:mi>W</m:mi>
		    <m:mi>k</m:mi>
		  </m:msup>
		</m:ci>
	      </m:apply>
	    </m:math> converges, then as 
	    <m:math>
	      <m:apply>
		<m:tendsto/>
		<m:ci>k</m:ci>
		<m:infinity/>
	      </m:apply>
	    </m:math>,
	    <m:math>
	      <m:apply>
		<m:approx/>
		<m:apply>
		  <m:mean/>
		  <m:ci>
		    <m:msup>
		      <m:mi>W</m:mi>
		      <m:mrow>
			<m:mi>k</m:mi>
			<m:mo>+</m:mo>
			<m:mn>1</m:mn>
		      </m:mrow>
		    </m:msup>
		  </m:ci>
		</m:apply>
		<m:apply>
		  <m:mean/>
		  <m:ci>
		    <m:msup>
		      <m:mi>W</m:mi>
		      <m:mi>k</m:mi>
		    </m:msup>
		  </m:ci>
		</m:apply>
	      </m:apply>
	    </m:math>, and
	    <m:math display="block">
	      <m:apply>
		<m:eq/>
		<m:apply>
		  <m:mean/>
		  <m:ci>
		    <m:msup>
		      <m:mi>W</m:mi>
		      <m:mi>∞</m:mi>
		    </m:msup>
		  </m:ci>
		</m:apply>
		<m:apply>
		  <m:plus/>
		  <m:apply>
		    <m:times/>
		    <m:apply>
		      <m:minus/>
		      <m:ci>I</m:ci>
		      <m:apply>
			<m:times/>
			<m:cn>2</m:cn>
			<m:ci>μ</m:ci>
			<m:ci>R</m:ci>
		      </m:apply>
		    </m:apply>
		    <m:apply>
		      <m:mean/>
		      <m:ci>
			<m:msup>
			  <m:mi>W</m:mi>
			  <m:mi>∞</m:mi>
			</m:msup>
		      </m:ci>
		    </m:apply>
		  </m:apply>
		  <m:apply>
		    <m:times/>
		    <m:cn>2</m:cn>
		    <m:ci>μ</m:ci>
		    <m:ci>P</m:ci>
		  </m:apply>
		</m:apply>
	      </m:apply>
	    </m:math>
	    <m:math display="block">
	      <m:apply>
		<m:eq/>
		<m:apply>
		  <m:times/>
		  <m:cn>2</m:cn>
		  <m:ci>μ</m:ci>
		  <m:ci>R</m:ci>
		  <m:apply>
		    <m:mean/>
		    <m:ci>
		      <m:msup>
			<m:mi>W</m:mi>
			<m:mi>∞</m:mi>
		      </m:msup>
		    </m:ci>
		  </m:apply>
		</m:apply>
		<m:apply>
		  <m:times/>
		  <m:cn>2</m:cn>
		  <m:ci>μ</m:ci>
		  <m:ci>P</m:ci>
		</m:apply>
	      </m:apply>
	    </m:math>
	    <m:math display="block">
	      <m:apply>
		<m:eq/>
		<m:apply>
		  <m:times/>
		  <m:ci>R</m:ci>
		  <m:apply>
		    <m:mean/>
		    <m:ci>
		      <m:msup>
			<m:mi>W</m:mi>
			<m:mi>∞</m:mi>
		      </m:msup>
		    </m:ci>
		  </m:apply>
		</m:apply>
		<m:ci>P</m:ci>
	      </m:apply>
	    </m:math> or
	    <m:math display="block">
	      <m:apply>
		<m:eq/>
		<m:apply>
		  <m:mean/>
		  <m:ci>
		    <m:msub>
		      <m:mi>W</m:mi>
		      <m:mi>opt</m:mi>
		    </m:msub>
		  </m:ci>
		</m:apply>
		<m:apply>
		  <m:times/>
		  <m:apply>
		    <m:inverse/>
		    <m:ci>R</m:ci>
		  </m:apply>
		  <m:ci>P</m:ci>
		</m:apply>
	      </m:apply>
	    </m:math> the Wiener solution!
	  </para>
	  <para id="para9">
	    So the LMS algorithm, <emphasis>if</emphasis> it
	    converges, gives filter coefficients which on average are
	    the Wiener coefficients! This is, of course, a desirable
	    result.
	  </para>
	</section>
      </section>
      <section id="sectb">
	<title>First-order stability</title>
	<para id="para10">
	  But does
	  <m:math>
	    <m:apply>
	      <m:mean/>
	      <m:ci>
		<m:msup>
		  <m:mi>W</m:mi>
		  <m:mi>k</m:mi>
		</m:msup>
	      </m:ci>
	    </m:apply>
	  </m:math> converge, or under what conditions?
	</para>
	<para id="para11">
	  Let's rewrite the analysis in term of 
	  <m:math>
	    <m:apply>
	      <m:mean/>
	      <m:ci>
		<m:msup>
		  <m:mi>V</m:mi>
		  <m:mi>k</m:mi>
		</m:msup>
	      </m:ci>
	    </m:apply>
	  </m:math>, the "mean coefficient error vector"
	  <m:math>
	    <m:apply>
	      <m:eq/>
	      <m:apply>
		<m:mean/>
		<m:ci>
		  <m:msup>
		    <m:mi>V</m:mi>
		    <m:mi>k</m:mi>
		  </m:msup>
		</m:ci>
	      </m:apply>
	      <m:apply>
		<m:minus/>
		<m:apply>
		  <m:mean/>
		  <m:ci>
		    <m:msup>
		      <m:mi>W</m:mi>
		      <m:mi>k</m:mi>
		    </m:msup>
		  </m:ci>
		</m:apply>
		<m:ci>
		  <m:msub>
		    <m:mi>W</m:mi>
		    <m:mi>opt</m:mi>
		  </m:msub>
		</m:ci>
	      </m:apply>
	    </m:apply>
	  </m:math>, where 
	  <m:math>
	    <m:ci>
	      <m:msub>
		<m:mi>W</m:mi>
		<m:mi>opt</m:mi>
	      </m:msub>
	    </m:ci>
	  </m:math> is the Wiener filter
	  <m:math display="block">
	    <m:apply>
	      <m:eq/>
	      <m:apply>
		<m:mean/>
		<m:ci>
		  <m:msup>
		    <m:mi>W</m:mi>
		    <m:mrow>
		      <m:mi>k</m:mi>
		      <m:mo>+</m:mo>
		      <m:mn>1</m:mn>
		    </m:mrow>
		  </m:msup>
		</m:ci>
	      </m:apply>
	      <m:apply>
		<m:plus/>
		<m:apply>
		  <m:minus/>
		  <m:apply>
		    <m:mean/>
		    <m:ci>
		      <m:msup>
			<m:mi>W</m:mi>
			<m:mi>k</m:mi>
		      </m:msup>
		    </m:ci>
		  </m:apply>
		  <m:apply>
		    <m:times/>
		    <m:cn>2</m:cn>
		    <m:ci>μ</m:ci>
		    <m:ci>R</m:ci>
		    <m:apply>
		      <m:mean/>
		      <m:ci>
			<m:msup>
			  <m:mi>W</m:mi>
			  <m:mi>k</m:mi>
			</m:msup>
		      </m:ci>
		    </m:apply>
		  </m:apply>
		</m:apply>
		<m:apply>
		  <m:times/>
		  <m:cn>2</m:cn>
		  <m:ci>μ</m:ci>
		  <m:ci>P</m:ci>
		</m:apply>
	      </m:apply>
	    </m:apply>
	  </m:math>
	  <m:math display="block">
	    <m:apply>
	      <m:eq/>
	      <m:apply>
		<m:minus/>
		<m:apply>
		  <m:mean/>
		  <m:ci>
		    <m:msup>
		      <m:mi>W</m:mi>
		      <m:mrow>
			<m:mi>k</m:mi>
			<m:mo>+</m:mo>
			<m:mn>1</m:mn>
		      </m:mrow>
		    </m:msup>
		  </m:ci>
		</m:apply>
		<m:ci>
		  <m:msub>
		    <m:mi>W</m:mi>
		    <m:mi>opt</m:mi>
		  </m:msub>
		</m:ci>
	      </m:apply>
	      <m:apply>
		<m:plus/>
		<m:apply>
		  <m:minus/>
		  <m:apply>
		    <m:mean/>
		    <m:ci>
		      <m:msup>
			<m:mi>W</m:mi>
			<m:mi>k</m:mi>
		      </m:msup>
		    </m:ci>
		  </m:apply>
		  <m:ci>
		    <m:msub>
		      <m:mi>W</m:mi>
		      <m:mi>opt</m:mi>
		    </m:msub>
		  </m:ci>
		</m:apply>
		<m:apply>
		  <m:minus/>
		  <m:apply>
		    <m:times/>
		    <m:cn>2</m:cn>
		    <m:ci>μ</m:ci>
		    <m:ci>R</m:ci>
		    <m:apply>
		      <m:mean/>
		      <m:ci>
			<m:msup>
			  <m:mi>W</m:mi>
			  <m:mi>k</m:mi>
			</m:msup>
		      </m:ci>
		    </m:apply>
		  </m:apply>
		</m:apply>
		<m:apply>
		  <m:minus/>
		  <m:apply>
		    <m:times/>
		    <m:cn>2</m:cn>
		    <m:ci>μ</m:ci>
		    <m:ci>R</m:ci>
		    <m:ci>
		      <m:msub>
			<m:mi>W</m:mi>
			<m:mi>opt</m:mi>
		      </m:msub>
		    </m:ci>
		  </m:apply>
		  <m:apply>
		    <m:times/>
		    <m:cn>2</m:cn>
		    <m:ci>μ</m:ci>
		    <m:ci>R</m:ci>
		    <m:ci>
		      <m:msub>
			<m:mi>W</m:mi>
			<m:mi>opt</m:mi>
		      </m:msub>
		    </m:ci>
		  </m:apply>
		</m:apply>
		<m:apply>
		  <m:times/>
		  <m:cn>2</m:cn>
		  <m:ci>μ</m:ci>
		  <m:ci>P</m:ci>
		</m:apply>
	      </m:apply>
	    </m:apply>
	  </m:math>
	  <m:math display="block">
	    <m:apply>
	      <m:eq/>
	      <m:apply>
		<m:mean/>
		<m:ci>
		  <m:msup>
		    <m:mi>V</m:mi>
		    <m:mrow>
		      <m:mi>k</m:mi>
		      <m:mo>+</m:mo>
		      <m:mn>1</m:mn>
		    </m:mrow>
		  </m:msup>
		</m:ci>
	      </m:apply>
	      <m:apply>
		<m:plus/>
		<m:apply>
		  <m:minus/>
		  <m:apply>
		    <m:mean/>
		    <m:ci>
		      <m:msup>
			<m:mi>V</m:mi>
			<m:mi>k</m:mi>
		      </m:msup>
		    </m:ci>
		  </m:apply>
		  <m:apply>
		    <m:times/>
		    <m:cn>2</m:cn>
		    <m:ci>μ</m:ci>
		    <m:ci>R</m:ci>
		    <m:apply>
		      <m:mean/>
		      <m:ci>
			<m:msup>
			  <m:mi>V</m:mi>
			  <m:mi>k</m:mi>
			</m:msup>
		      </m:ci>
		    </m:apply>
		  </m:apply>
		</m:apply>
		<m:apply>
		  <m:minus/>
		  <m:apply>
		    <m:times/>
		    <m:cn>2</m:cn>
		    <m:ci>μ</m:ci>
		    <m:ci>R</m:ci>
		    <m:ci>
		      <m:msub>
			<m:mi>W</m:mi>
			<m:mi>opt</m:mi>
		      </m:msub>
		    </m:ci>
		  </m:apply>
		</m:apply>
		<m:apply>
		  <m:times/>
		  <m:cn>2</m:cn>
		  <m:ci>μ</m:ci>
		  <m:ci>P</m:ci>
		</m:apply>
	      </m:apply>
	    </m:apply>
	  </m:math>
	  Now
	  <m:math>
	    <m:apply>
	      <m:eq/>
	      <m:ci>
		<m:msub>
		  <m:mi>W</m:mi>
		  <m:mi>opt</m:mi>
		</m:msub>
	      </m:ci>
	      <m:apply>
		<m:times/>
		<m:apply>
		  <m:inverse/>
		  <m:ci>R</m:ci>
		  <m:ci>P</m:ci>
		</m:apply>
	      </m:apply>
	    </m:apply>
	  </m:math>, so
	  <m:math display="block">
	    <m:apply>
	      <m:eq/>
	      <m:apply>
		<m:mean/>
		<m:ci>
		  <m:msup>
		    <m:mi>V</m:mi>
		    <m:mrow>
		      <m:mi>k</m:mi>
		      <m:mo>+</m:mo>
		      <m:mn>1</m:mn>
		    </m:mrow>
		  </m:msup>
		</m:ci>
	      </m:apply>
	      <m:apply>
		<m:plus/>
		<m:apply>
		  <m:minus/>
		  <m:apply>
		    <m:mean/>
		    <m:ci>
		      <m:msup>
			<m:mi>V</m:mi>
			<m:mi>k</m:mi>
		      </m:msup>
		    </m:ci>
		  </m:apply>
		  <m:apply>
		    <m:times/>
		    <m:cn>2</m:cn>
		    <m:ci>μ</m:ci>
		    <m:ci>R</m:ci>
		    <m:apply>
		      <m:mean/>
		      <m:ci>
			<m:msup>
			  <m:mi>V</m:mi>
			  <m:mi>k</m:mi>
			</m:msup>
		      </m:ci>
		    </m:apply>
		  </m:apply>
		</m:apply>
		<m:apply>
		  <m:minus/>
		  <m:apply>
		    <m:times/>
		    <m:cn>2</m:cn>
		    <m:ci>μ</m:ci>
		    <m:ci>R</m:ci>
		    <m:apply>
		      <m:inverse/>
		      <m:ci>R</m:ci>
		    </m:apply>
		    <m:ci>P</m:ci>
		  </m:apply>
		</m:apply>
		<m:apply>
		  <m:times/>
		  <m:cn>2</m:cn>
		  <m:ci>μ</m:ci>
		  <m:ci>P</m:ci>
		</m:apply>
	      </m:apply>
	      <m:apply>
		<m:times/>
		<m:apply>
		  <m:minus/>
		  <m:ci>I</m:ci>
		  <m:apply>
		    <m:times/>
		    <m:cn>2</m:cn>
		    <m:ci>μ</m:ci>
		    <m:ci>R</m:ci>
		  </m:apply>
		</m:apply>
		<m:apply>
		  <m:mean/>
		  <m:ci>
		    <m:msup>
		      <m:mi>V</m:mi>
		      <m:mi>k</m:mi>
		    </m:msup>
		  </m:ci>
		</m:apply>
	      </m:apply>
	    </m:apply>
	  </m:math>
	 We wish to know under what conditions
	  <m:math>
	    <m:apply>
	      <m:tendsto/>
	      <m:apply>
		<m:mean/>
		<m:ci>
		  <m:msup>
		    <m:mi>V</m:mi>
		    <m:mrow>
		      <m:mi>k</m:mi>
		      <m:mo>→</m:mo>
		      <m:mi>∞</m:mi>
		    </m:mrow>
		  </m:msup>
		</m:ci>
	      </m:apply>
	      <m:apply>
		<m:mean/>
		<m:cn>0</m:cn>
	      </m:apply>
	    </m:apply>
	  </m:math>?
	</para>
	<section id="linear">
	  <title>Linear Algebra Fact</title>
	  <para id="para11a">
	    Since <m:math><m:ci>R</m:ci></m:math> is positive
	    definite, real, and symmetric, all the eigenvalues are
	    real and positive. Also, we can write
	    <m:math><m:ci>R</m:ci></m:math> as
	    <m:math>
	      <m:apply>
		<m:mo>Λ</m:mo>
		<m:apply>
		  <m:inverse/>
		  <m:ci>Q</m:ci>
		</m:apply>
		<m:ci>Q</m:ci>
	      </m:apply>
	    </m:math>, where <m:math><m:ci>Λ</m:ci></m:math> is
	    a diagonal matrix with diagonal entries
	    <m:math>
	      <m:ci>
		<m:msub>
		  <m:mi>λ</m:mi>
		  <m:mi>i</m:mi>
		</m:msub>
	      </m:ci>
	    </m:math> equal to the eigenvalues of
	    <m:math><m:ci>R</m:ci></m:math>, and
	    <m:math><m:ci>Q</m:ci></m:math> is a unitary matrix with
	    rows equal to the eigenvectors corresponding to the
	    eigenvalues of <m:math><m:ci>R</m:ci></m:math>.
	  </para>
	  <para id="para12">
	    Using this fact,
	    <m:math display="block">
	      <m:apply>
		<m:eq/>
		<m:ci>
		  <m:msup>
		    <m:mi>V</m:mi>
		    <m:mrow>
		      <m:mi>k</m:mi>
		      <m:mo>+</m:mo>
		      <m:mn>1</m:mn>
		    </m:mrow>
		  </m:msup>
		</m:ci>
		<m:apply>
		  <m:times/>
		  <m:apply>
		    <m:minus/>
		    <m:ci>I</m:ci>
		    <m:apply>
		      <m:times/>
		      <m:cn>2</m:cn>
		      <m:ci>μ</m:ci>
		      <m:apply>
			<m:mo>Λ</m:mo>
			<m:apply>
			  <m:inverse/>
			  <m:ci>Q</m:ci>
			</m:apply>
			<m:ci>Q</m:ci>
		      </m:apply>
		    </m:apply>
		  </m:apply>
		  <m:ci>
		    <m:msup>
		      <m:mi>V</m:mi>
		      <m:mi>k</m:mi>
		    </m:msup>
		  </m:ci>
		</m:apply>
	      </m:apply>
	    </m:math>
	    multiplying both sides through on the left by
	    <m:math><m:ci>Q</m:ci></m:math>: we get
	    <m:math display="block">
	      <m:apply>
		<m:eq/>
		<m:apply>
		  <m:times/>
		  <m:ci>Q</m:ci>
		  <m:apply>
		    <m:mean/>
		    <m:ci>
		      <m:msup>
			<m:mi>V</m:mi>
			<m:mrow>
			  <m:mi>k</m:mi>
			  <m:mo>+</m:mo>
			  <m:mn>1</m:mn>
			</m:mrow>
		      </m:msup>
		    </m:ci>
		  </m:apply>
		</m:apply>
		<m:apply>
		  <m:times/>
		  <m:apply>
		    <m:minus/>
		    <m:ci>Q</m:ci>
		    <m:apply>
		      <m:times/>
		      <m:cn>2</m:cn>
		      <m:ci>μ</m:ci>
		      <m:ci>Λ</m:ci>
		      <m:ci>Q</m:ci>
		    </m:apply>
		  </m:apply>
		  <m:apply>
		    <m:mean/>
		    <m:ci>
		      <m:msup>
			<m:mi>V</m:mi>
			<m:mi>k</m:mi>
		      </m:msup>
		    </m:ci>
		  </m:apply>
		</m:apply>
		<m:apply>
		  <m:times/>
		  <m:apply>
		    <m:minus/>
		    <m:cn>1</m:cn>
		    <m:apply>
		      <m:times/>
		      <m:cn>2</m:cn>
		      <m:ci>μ</m:ci>
		      <m:ci>Λ</m:ci>
		    </m:apply>
		  </m:apply>
		  <m:ci>Q</m:ci>
		  <m:apply>
		    <m:mean/>
		    <m:ci>
		      <m:msup>
			<m:mi>V</m:mi>
			<m:mi>k</m:mi>
		      </m:msup>
		    </m:ci>
		  </m:apply>
		</m:apply>
	      </m:apply>
	    </m:math>
	    Let 
	    <m:math>
	      <m:apply>
		<m:eq/>
		<m:ci>
		  <m:msup>
		    <m:mi>V</m:mi>
		    <m:mi>'</m:mi>
		  </m:msup>
		</m:ci>
		<m:apply>
		  <m:times/>
		  <m:ci>Q</m:ci>
		  <m:ci>V</m:ci>
		</m:apply>
	      </m:apply>
	    </m:math>:
	    <m:math display="block">
	      <m:apply>
		<m:eq/>
		<m:ci>
		  <m:msup>
		    <m:mi>V</m:mi>
		    <m:mrow>
		      <m:mi>'</m:mi>
		      <m:mi>k</m:mi>
		      <m:mo>+</m:mo>
		      <m:mn>1</m:mn>
		    </m:mrow>
		  </m:msup>
		</m:ci>
		<m:apply>
		  <m:times/>
		  <m:apply>
		    <m:minus/>
		    <m:cn>1</m:cn>
		    <m:apply>
		      <m:times/>
		      <m:cn>2</m:cn>
		      <m:ci>μ</m:ci>
		      <m:ci>Λ</m:ci>
		    </m:apply>
		  </m:apply>
		  <m:ci>
		    <m:msup>
		      <m:mi>V</m:mi>
		      <m:mrow>
			<m:mi>'</m:mi>
			<m:mi>k</m:mi>
		      </m:mrow>
		    </m:msup>
		  </m:ci>
		</m:apply>
	      </m:apply>
	    </m:math>
	    Note that
	    <m:math>
	      <m:ci>
		<m:msup>
		  <m:mi>V</m:mi>
		  <m:mi>'</m:mi>
		</m:msup>
	      </m:ci>
	    </m:math> is simply <m:math><m:ci>V</m:ci></m:math> in a
	    rotated coordinate set in
	    <m:math>
	      <m:apply>
		<m:power/>
		<m:ci>ℝ</m:ci>
		<m:ci>m</m:ci>
	      </m:apply>
	    </m:math>, so convergence of 
	    <m:math>
	      <m:ci>
		<m:msup>
		  <m:mi>V</m:mi>
		  <m:mi>'</m:mi>
		</m:msup>
	      </m:ci>
	    </m:math>
	    implies convergence of <m:math><m:ci>V</m:ci></m:math>.
	  </para>
	  <para id="para13">
	    Since
	    <m:math>
	      <m:apply>
		<m:minus/>
		<m:cn>1</m:cn>
		<m:apply>
		  <m:times/>
		  <m:cn>2</m:cn>
		  <m:ci>μ</m:ci>
		  <m:ci>Λ</m:ci>
		</m:apply>
	      </m:apply>
	    </m:math> is diagonal, all elements of 
	    <m:math>
	      <m:ci>
		<m:msup>
		  <m:mi>V</m:mi>
		  <m:mi>'</m:mi>
		</m:msup>
	      </m:ci>
	    </m:math> evolve independently of each other. Convergence
	    (stability) bolis down to whether all
	    <m:math><m:ci>M</m:ci></m:math> of these scalar,
	    first-order difference equations are stable, and thus
	    <m:math>
	      <m:apply>
		<m:mo>→</m:mo>
		<m:cn>0</m:cn>
	      </m:apply>
	    </m:math>.
	    <m:math display="block">
	      <m:apply>
		<m:forall/>
		<m:bvar><m:ci>i</m:ci></m:bvar>
		<m:condition>
		  <m:apply>
		    <m:eq/>
		    <m:ci>i</m:ci>
		    <m:list>
		      <m:cn>1</m:cn>
		      <m:cn>2</m:cn>
		      <m:ci>…</m:ci>
		      <m:ci>M</m:ci>
		    </m:list>
		  </m:apply>
		</m:condition>
		<m:apply>
		  <m:eq/>
		  <m:ci>
		    <m:msubsup>
		      <m:mi>V</m:mi>
		      <m:mi>i</m:mi>
		      <m:mrow>
			<m:mi>'</m:mi>
			<m:mi>k</m:mi>
			<m:mo>+</m:mo>
			<m:mn>1</m:mn>
		      </m:mrow>
		    </m:msubsup>
		  </m:ci>
		  <m:apply>
		    <m:times/>
		    <m:apply>
		      <m:minus/>
		      <m:cn>1</m:cn>
		      <m:apply>
			<m:times/>
			<m:cn>2</m:cn>
			<m:ci>μ</m:ci>
			<m:ci>
			  <m:msub>
			    <m:mi>λ</m:mi>
			    <m:mi>i</m:mi>
			  </m:msub>
			</m:ci>
		      </m:apply>
		    </m:apply>
		    <m:ci>
		      <m:msubsup>
			<m:mi>V</m:mi>
			<m:mi>i</m:mi>
			<m:mrow>
			  <m:mi>'</m:mi>
			  <m:mi>k</m:mi>
			</m:mrow>
		      </m:msubsup>
		    </m:ci>
		  </m:apply>
		</m:apply>
	      </m:apply>
	    </m:math>
	    These equations converge to zero if 
	    <m:math>
	      <m:apply>
		<m:lt/>
		<m:apply>
		  <m:abs/>
		  <m:apply>
		    <m:minus/>
		    <m:cn>1</m:cn>
		    <m:apply>
		      <m:times/>
		      <m:cn>2</m:cn>
		      <m:ci>μ</m:ci>
		      <m:ci>
			<m:msub>
			  <m:mi>λ</m:mi>
			  <m:mi>i</m:mi>
			</m:msub>
		      </m:ci>
		    </m:apply>
		  </m:apply>
		</m:apply>
		<m:cn>1</m:cn>
	      </m:apply>
	    </m:math>, or
	    <m:math>
	      <m:apply>
		<m:forall/>
		<m:bvar>
		  <m:ci>i</m:ci>
		</m:bvar>
		<m:apply>
		  <m:lt/>
		  <m:apply>
		    <m:abs/>
		    <m:apply>
		      <m:times/>
		      <m:ci>μ</m:ci>
		      <m:ci>
			<m:msub>
			  <m:mi>λ</m:mi>
			  <m:mi>i</m:mi>
			</m:msub>
		      </m:ci>
		    </m:apply>
		  </m:apply>
		  <m:cn>1</m:cn>
		</m:apply>
	      </m:apply>
	    </m:math>
	    <m:math><m:ci>μ</m:ci></m:math>
	    and
	    <m:math>
	      <m:ci>
		<m:msub>
		  <m:mi>λ</m:mi>
		  <m:mi>i</m:mi>
		</m:msub>
	      </m:ci>
	    </m:math>
	    are positive, so we require 
	    <m:math>
	      <m:apply>
		<m:forall/>
		<m:bvar>
		  <m:ci>i</m:ci>
		</m:bvar>
		<m:apply>
		  <m:lt/>
		  <m:ci>μ</m:ci>
		  <m:apply>
		    <m:divide/>
		    <m:cn>1</m:cn>
		    <m:ci>
		      <m:msub>
			<m:mi>λ</m:mi>
			<m:mi>i</m:mi>
		      </m:msub>
		    </m:ci>
		  </m:apply>
		</m:apply>
	      </m:apply>
	    </m:math> so for convergence in the mean of the LMS
	    adaptive filter, we require
	    <equation id="equa1">
	      <m:math>
		<m:apply>
		  <m:lt/>
		  <m:ci>μ</m:ci>
		  <m:apply>
		    <m:divide/>
		    <m:cn>1</m:cn>
		    <m:ci>
		      <m:msub>
			<m:mi>λ</m:mi>
			<m:mi>max</m:mi>
		      </m:msub>
		    </m:ci>
		  </m:apply>
		</m:apply>
	      </m:math>
	    </equation>
	    This is an elegant theoretical result, but in practice, we
	    may not know
	    <m:math>
	      <m:ci>
		<m:msub>
		  <m:mi>λ</m:mi>
		  <m:mi>max</m:mi>
		</m:msub>
	      </m:ci>
	    </m:math>, it may be time-varying, and we certainly won't
	    want to compute it. However, another useful mathematical
	    fact comes to the rescue...
	    <m:math display="block">
	      <m:apply>
		<m:eq/>
		<m:apply>
		  <m:ci type="fn">tr</m:ci>
		  <m:ci type="matrix">R</m:ci>
		</m:apply>
		<m:apply>
		  <m:sum/>
		  <m:bvar>
		    <m:ci>i</m:ci>
		  </m:bvar>
		  <m:lowlimit>
		    <m:cn>1</m:cn>
		  </m:lowlimit>
		  <m:uplimit>
		    <m:ci>M</m:ci>
		  </m:uplimit>
		  <m:ci>
		    <m:msub>
		      <m:mi>r</m:mi>
		      <m:mi>ii</m:mi>
		    </m:msub>
		  </m:ci>
		</m:apply>
		<m:apply>
		  <m:geq/>
		  <m:apply>
		    <m:sum/>
		    <m:bvar>
		      <m:ci>i</m:ci>
		    </m:bvar>
		    <m:lowlimit>
		      <m:cn>1</m:cn>
		    </m:lowlimit>
		    <m:uplimit>
		      <m:ci>M</m:ci>
		    </m:uplimit>
		    <m:ci>
		      <m:msub>
			<m:mi>λ</m:mi>
			<m:mi>i</m:mi>
		      </m:msub>
		    </m:ci>
		  </m:apply>
		  <m:ci>
		    <m:msub>
		      <m:mi>λ</m:mi>
		      <m:mi>max</m:mi>
		    </m:msub>
		  </m:ci>
		</m:apply>
	      </m:apply>
	    </m:math>
	    Since the eigenvalues are all positive and real.    
	  </para>

	  <para id="para14">
	    For a correlation matrix, 
	    <m:math>
	      <m:apply>
		<m:forall/>
		<m:bvar>
		  <m:ci>i</m:ci>
		</m:bvar>
		<m:condition>
		  <m:apply>
		    <m:in/>
		    <m:ci>i</m:ci>
		    <m:set>
		      <m:cn>1</m:cn>
		      <m:ci>M</m:ci>
		    </m:set>
		  </m:apply>
		</m:condition>
		<m:apply>
		  <m:eq/>
		  <m:ci>
		    <m:msub>
		      <m:mi>r</m:mi>
		      <m:mi>ii</m:mi>
		    </m:msub>
		  </m:ci>
		  <m:apply>
		    <m:ci type="fn">r</m:ci>
		    <m:cn>0</m:cn>
		  </m:apply>
		</m:apply>
	      </m:apply>
	    </m:math>. So
	    <m:math>
	      <m:apply>
		<m:eq/>
		<m:apply>
		  <m:ci type="fn">tr</m:ci>
		  <m:ci type="matrix">R</m:ci>
		</m:apply>
		<m:apply>
		  <m:times/>
		  <m:ci>M</m:ci>
		  <m:apply>
		    <m:ci type="fn">r</m:ci>
		    <m:cn>0</m:cn>
		  </m:apply>
		</m:apply>
		<m:apply>
		  <m:times/>
		  <m:ci>M</m:ci>
		  <m:apply>
		    <m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#expectedvalue"/>
		    <m:apply>
		      <m:times/>
		      <m:ci>
			<m:msub>
			  <m:mi>x</m:mi>
			  <m:mi>k</m:mi>
			</m:msub>
		      </m:ci>
		      <m:ci>
			<m:msub>
			  <m:mi>x</m:mi>
			  <m:mi>k</m:mi>
			</m:msub>
		      </m:ci>
		    </m:apply>
		  </m:apply>
		</m:apply>
	      </m:apply>
	    </m:math>. We can easily estimate
	    <m:math>
	      <m:apply>
		<m:ci type="fn">r</m:ci>
		<m:cn>0</m:cn>
	      </m:apply>
	    </m:math> with
	    <m:math>
	      <m:apply>
		<m:ci type="fn">O</m:ci>
		<m:cn>1</m:cn>
	      </m:apply>
	    </m:math> computations/sample, so in practice we might
	    require
	    <m:math display="block">
	      <m:apply>
		<m:lt/>
		<m:ci>μ</m:ci>
		<m:apply>
		  <m:divide/>
		  <m:cn>1</m:cn>
		  <m:apply>
		    <m:times/>
		    <m:ci>M</m:ci>
		    <m:apply>
		      <m:csymbol definitionURL="http://cnx.rice.edu/cd/cnxmath.ocd#estimate"/>
		      <m:apply>
			<m:ci type="fn">r</m:ci>
			<m:cn>0</m:cn>
		      </m:apply>
		    </m:apply>
		  </m:apply>
		</m:apply>
	      </m:apply>
	    </m:math> as a conservative bound, and perhaps adapt
	    <m:math><m:ci>μ</m:ci></m:math> accordingly with time.
	  </para>
	    
	</section>

      </section>

      <section id="sectc">
	<title>Rate of convergence</title>
	<para id="para15">
	  Each of the modes decays as
	  <m:math display="block">
	    <m:apply>
	      <m:power/>
	      <m:apply>
		<m:minus/>
		<m:cn>1</m:cn>
		<m:apply>
		  <m:times/>
		  <m:cn>2</m:cn>
		  <m:ci>μ</m:ci>
		  <m:ci>
		    <m:msub>
		      <m:mi>λ</m:mi>
		      <m:mi>i</m:mi>
		    </m:msub>
		  </m:ci>
		</m:apply>
	      </m:apply>
	      <m:ci>k</m:ci>
	    </m:apply>
	  </m:math>
	  <note type="Good news" id="idp9898304"><label>Good news</label>The <emphasis>initial</emphasis> rate
	  of convergence is dominated by the fastest mode
	    <m:math>
	      <m:apply>
		<m:minus/>
		<m:cn>1</m:cn>
		<m:apply>
		  <m:times/>
		  <m:cn>2</m:cn>
		  <m:ci>μ</m:ci>
		  <m:ci>
		    <m:msub>
		      <m:mi>λ</m:mi>
		      <m:mi>max</m:mi>
		    </m:msub>
		  </m:ci>
		</m:apply>
	      </m:apply>
	    </m:math>. This is not surprising, since a dradient
	    descent method goes "downhill" in the steepest direction
	  </note>
	  <note type="Bad news" id="idp9302672"><label>Bad news</label>
	    The <emphasis>final</emphasis> rate of convergence is
	    dominated by the slowest mode
	    <m:math>
	      <m:apply>
		<m:minus/>
		<m:cn>1</m:cn>
		<m:apply>
		  <m:times/>
		  <m:cn>2</m:cn>
		  <m:ci>μ</m:ci>
		  <m:ci>
		    <m:msub>
		      <m:mi>λ</m:mi>
		      <m:mi>min</m:mi>
		    </m:msub>
		  </m:ci>
		</m:apply>
	      </m:apply>
	    </m:math>. For small
	    <m:math>
	      <m:ci>
		<m:msub>
		  <m:mi>λ</m:mi>
		  <m:mi>min</m:mi>
		</m:msub>
	      </m:ci>
	    </m:math>, it can take a long time for LMS to converge.
	  </note>
	  Note that the convergence behavior depends on the data (via
	  <m:math><m:ci type="matrix">R</m:ci></m:math>). LMS converges
	  relatively quickly for roughly equal eigenvalues. Unequal
	  eigenvalues slow LMS down a lot.
	</para>
      </section>
    </section>
  </content>


  <bib:file>
    <bib:entry id="MacchiandEweda">
      <bib:article>
	<bib:author>O. Macchi and E. Eweda</bib:author>
	<bib:title>Second-Order Convergence Analysis of Stochastic 
	  Adaptive Linear Filtering</bib:title>
	<bib:journal>IEEE Trans. on Automatic Controls</bib:journal>
	<bib:year>Jan 1983</bib:year>
	<bib:volume>AC-28 #1</bib:volume>
	<bib:pages>76-85</bib:pages>
      </bib:article>
    </bib:entry>					
  </bib:file>
  
</document>